{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f208dd03-8f80-4f54-b18e-26a720388a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training logistic regression on reference data embedded by STATE (tabula sapiens)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a62a01-44da-4c99-be7d-61a29c9e6472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports \n",
    "import importlib\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "\n",
    "from scipy import sparse\n",
    "from joblib import dump, load\n",
    "\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb7d07e-c80f-4fb6-bc29-151063098e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e3632f6-7898-4989-8942-91aff0b4438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSP Anndatas file path\n",
    "TSP_FILE_PATH = '/large_storage/ctc/public/scBasecamp/tabula_sapiens/GeneFull_Ex50pAS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "617fcc8a-fe85-43c0-9b2b-1c2bb8ba9e9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TSP state embeddings\n",
    "STATE_TSP_FILE_PATH = '/large_storage/ctc/userspace/rohankshah/tabula_sapiens/tabula_sapiens_with_state.parquet'\n",
    "state_embeds = pd.read_parquet(STATE_TSP_FILE_PATH, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ae87f8d8-9ef2-4e26-98c3-cfe337540cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 833668/833668 [00:00<00:00, 1570497.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create an identifier\n",
    "state_embeds['tissue'] = state_embeds['dataset'].progress_apply(lambda dataset: dataset.split('_')[1])\n",
    "state_embeds['barcode'] = state_embeds['cell'].values\n",
    "state_embeds['identifier'] = (\n",
    "    state_embeds['dataset']\n",
    "    .str.replace(r'_S\\d+_', '_', regex=True)\n",
    "    .str.replace(r'_GeneFull_Ex50pAS$', '', regex=True)\n",
    "    # .str.replace(r'_[^_]*etc[^_]*_', '_', regex=True, flags=re.IGNORECASE)\n",
    ") + '_' + state_embeds['barcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "21af992a-3be1-4fe5-99f7-327180ff68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def remove_integers_from_list(in_string):\n",
    "    '''\n",
    "    Remove any integers from the input string\n",
    "    '''\n",
    "    return re.sub(r'\\d+', '', in_string)\n",
    "\n",
    "def get_tissues_list():\n",
    "    '''\n",
    "    Get list of tissues in tabula sapiens\n",
    "    '''\n",
    "    all_tsp_dirs = os.listdir(TSP_FILE_PATH)\n",
    "    tissues = []\n",
    "    for file_name in all_tsp_dirs:\n",
    "        tissue = remove_integers_from_list(file_name.split('_')[1]).lower()\n",
    "        if tissue not in tissues:\n",
    "            tissues.append(tissue)\n",
    "    return tissues\n",
    "    \n",
    "def get_tsp_files(tissue=None):\n",
    "    '''\n",
    "    Get list of TSP files for a given tissue\n",
    "    '''\n",
    "    all_tsp_dirs = os.listdir(TSP_FILE_PATH)\n",
    "    if tissue == 'lymphnode':\n",
    "        tsp_filtered = list(filter(lambda filename: remove_integers_from_list(filename.split('_')[1]).lower() == tissue.lower() or remove_integers_from_list(filename.split('_')[1]).lower() == 'lymphnodes', all_tsp_dirs))\n",
    "    else:\n",
    "        tsp_filtered = list(filter(lambda filename: remove_integers_from_list(filename.split('_')[1]).lower() == tissue.lower(), all_tsp_dirs))\n",
    "    return tsp_filtered\n",
    "\n",
    "def get_ref_adata(file_name):\n",
    "    '''\n",
    "    Get reference tabula sapiens data to train on\n",
    "    '''\n",
    "    adata = sc.read_h5ad(f'{TSP_FILE_PATH}/{file_name}')\n",
    "    return adata\n",
    "\n",
    "def merge_anndatas(file_list=None):\n",
    "    '''\n",
    "    Read in all reference anndatas and put them together\n",
    "    '''\n",
    "    adatas = []\n",
    "    for file_name in file_list:\n",
    "        adata = get_ref_adata(file_name)\n",
    "        adatas.append(adata)\n",
    "    ref_adata = ad.concat(adatas, merge='same')\n",
    "    ref_adata.obs.rename(columns={'Unnamed: 0': 'identifier'}, inplace=True)\n",
    "    return ref_adata\n",
    "\n",
    "def remove_null_cts(adata):\n",
    "    '''\n",
    "    Remove the entries with nan, unknown, or null cell types\n",
    "    '''\n",
    "    cleaned_adata = adata[(adata.obs.cell_type != 'nan') & (adata.obs.cell_type != 'unknown') & (~adata.obs.cell_type.isnull())].copy()\n",
    "    return cleaned_adata\n",
    "\n",
    "def align_embeddings(ref_adata, state_embeds, identifier_col):\n",
    "    '''\n",
    "    Align cells from state embeddings dataframe and align them with anndata\n",
    "    '''\n",
    "    if 'nan' in ref_adata.obs[identifier_col].values:\n",
    "        logging.error(\"Null identifiers exist in the reference data\")\n",
    "        return\n",
    "    \n",
    "    ref_adata.obs[identifier_col] = ref_adata.obs[identifier_col].astype(str)\n",
    "    state_embeds[identifier_col] = state_embeds[identifier_col].astype(str)\n",
    "\n",
    "    mask = ~ref_adata.obs.duplicated(subset=identifier_col, keep='first')\n",
    "    ref_adata = ref_adata[mask].copy()\n",
    "    \n",
    "    common_ids = set(ref_adata.obs[identifier_col]).intersection(set(state_embeds[identifier_col]))\n",
    "\n",
    "    if len(ref_adata.obs[identifier_col].unique()) != len(common_ids):\n",
    "        logging.warning(\"Cells in reference data not included in common ids\")\n",
    "\n",
    "    ref_adata = ref_adata[ref_adata.obs[identifier_col].isin(common_ids)].copy()\n",
    "    df_filtered = state_embeds[state_embeds[identifier_col].isin(common_ids)].copy()\n",
    "    df_filtered = df_filtered.set_index(identifier_col)\n",
    "    df_filtered = df_filtered.loc[ref_adata.obs[identifier_col]]\n",
    "    X_embed = df_filtered.iloc[:, 1:2059].to_numpy()\n",
    "    \n",
    "    assert X_embed.shape[0] == ref_adata.n_obs, \"Mismatch in number of cells and embeddings\"\n",
    "    \n",
    "    ref_adata.obsm['X_state'] = X_embed\n",
    "\n",
    "    return ref_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc9738-52c1-4b0a-9f48-c8a6c75f86fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the list of tissues to make models for\n",
    "tissues = get_tissues_list()\n",
    "output_model_dir = \"output/classifiers\"\n",
    "output_adata_dir = \"output/adatas_embedded\"\n",
    "ignore_prev = False\n",
    "to_skip_list = ['endopancreas', 'exopancreas', 'lymphnodes', 'wholeblood']\n",
    "barcode_aligned = ['eye', 'mammary', 'myometrium', 'endometrium']\n",
    "\n",
    "for i in tqdm(range(len(tissues))):\n",
    "    # Get the tissue from tissues list\n",
    "    tissue = tissues[i]\n",
    "\n",
    "    if tissue in to_skip_list:\n",
    "        logging.info(f\"{tissue} in the skip list, continuing to the next tissue\")\n",
    "        continue\n",
    "    \n",
    "    # Retrieve list of tsp files for a corresponding tissue\n",
    "    files_list = get_tsp_files(tissue)\n",
    "    if f'TSP_{tissue}.h5ad' not in os.listdir(output_adata_dir):\n",
    "        logging.info(f\"Processing {tissue} TSP data...\")\n",
    "        ref_adata = merge_anndatas(files_list)\n",
    "        logging.info(\"Merged anndatas\")\n",
    "        \n",
    "        ref_adata_processed = remove_null_cts(ref_adata)\n",
    "        logging.info(\"Removed null cell types\")\n",
    "\n",
    "        if tissue in barcode_aligned:\n",
    "            mask = ~ref_adata_processed.obs.duplicated(subset=['barcode'], keep=False)\n",
    "            ref_adata_processed = ref_adata_processed[mask].copy()\n",
    "            embeds = state_embeds[state_embeds['identifier'].str.contains(tissue, case=False)].copy()\n",
    "            embeds.drop_duplicates(subset=['barcode'], keep=False, inplace=True)\n",
    "            ref_adata_embedded = align_embeddings(ref_adata_processed, embeds, identifier_col='barcode')\n",
    "            print(f'{tissue} data shape {ref_adata_embedded.shape}')\n",
    "        else:\n",
    "            ref_adata_embedded = align_embeddings(ref_adata_processed, state_embeds, identifier_col='identifier')\n",
    "        logging.info(\"Aligned STATE embeddings with reference anndata\")\n",
    "        \n",
    "        ref_adata_embedded.write(output_adata_dir + f'/TSP_{tissue}.h5ad')\n",
    "        logging.info(f\"Successfully wrote anndata to {output_adata_dir}\")\n",
    "    else:\n",
    "        logging.info(f\"{tissue} already has embeddings\")\n",
    "\n",
    "    if f'{tissue}_ref_model_logreg.joblib' not in os.listdir(output_model_dir) or ignore_prev:\n",
    "        logging.info(\"Training logistic regression classifier...\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "                            (\"scaler\", StandardScaler()),\n",
    "                            (\"logreg\", LogisticRegression(max_iter=1000)),\n",
    "                        ])\n",
    "\n",
    "        ref_adata_embedded = sc.read_h5ad(output_adata_dir + f'/TSP_{tissue}.h5ad')\n",
    "            \n",
    "        embeddings, labels = ref_adata_embedded.obsm[\"X_state\"], ref_adata_embedded.obs[\"cell_type\"]\n",
    "        pipeline.fit(embeddings, labels)\n",
    "        logging.info(\"Finished training logistic regression classifier\")\n",
    "        \n",
    "        # Save pipeline\n",
    "        dump(pipeline, output_model_dir + f'/{tissue}_ref_model_logreg.joblib')\n",
    "        logging.info(f\"Successfully saved model to {output_model_dir}\")\n",
    "    else:\n",
    "        logging.info(f\"Logistic regression classifier for {tissue} tissue already exists\")\n",
    "\n",
    "    logging.info(f\"All steps completed for {tissue}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
